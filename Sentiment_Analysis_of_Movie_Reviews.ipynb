{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Overview:\n",
        "\n",
        "The goal of this project is to perform sentiment analysis on movie reviews to classify them as either positive or negative. I preprocess the text data, extract features, and use a machine learning model to classify the reviews.\n",
        "\n",
        "The dataset we'll use is the Large Movie Review Dataset, which can be found here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "I am utilizing two approaches:\n",
        "- Bag of Words with classical Machine Learning (Logistic Regression)\n",
        "- Word Embeddings (Global Vectors) with LSTM based model (Deep Learning)"
      ],
      "metadata": {
        "id": "IoqmT3g6cet3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Citation:\n",
        "\n",
        "Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., & Potts, C. (2011). Learning Word Vectors for Sentiment Analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (pp. 142-150). Portland, Oregon, USA: Association for Computational Linguistics. Retrieved from http://www.aclweb.org/anthology/P11-1015"
      ],
      "metadata": {
        "id": "pBN9N-sTlNs4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LTQqfyudcd_L"
      },
      "outputs": [],
      "source": [
        "#! wget --header=\"Host: ai.stanford.edu\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\" --header=\"Accept-Language: en-US,en;q=0.9,ur;q=0.8\" --header=\"Referer: http://ai.stanford.edu/~amaas/data/sentiment/\" \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\" -c -O 'aclImdb_v1.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!tar -xvzf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "nFL8FlnCdqGB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data"
      ],
      "metadata": {
        "id": "hRUmEAg6eaCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "TEsY5LUreThw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_reviews(path):\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    \n",
        "    for label in ['pos', 'neg']:\n",
        "        folder = os.path.join(path, label)\n",
        "        for file in glob.glob(os.path.join(folder, '*.txt')):\n",
        "            with open(file, 'r', encoding='utf-8') as f:\n",
        "                reviews.append(f.read())\n",
        "                labels.append(1 if label == 'pos' else 0)\n",
        "                \n",
        "    return reviews, labels\n",
        "\n",
        "train_path = './aclImdb/train'\n",
        "test_path = './aclImdb/test'\n",
        "\n",
        "train_reviews, train_labels = read_reviews(train_path)\n",
        "test_reviews, test_labels = read_reviews(test_path)\n"
      ],
      "metadata": {
        "id": "OBinuU61c7sl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample review\n",
        "train_reviews[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "DW80aUUueqCr",
        "outputId": "af66c03b-0f9c-4e05-a1e5-be2d6dee325a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Following my experience of Finland for slightly more than a week, I\\'d say this movie depicts the nature of the Finnish society very accurately. Especially the young-couple-with-a-baby-having-serious-issues phenomenon is very familiar to me, as I witnessed the exact same thing in person when I was in Finland. The relationships and problems of people, fragility of the marriage institution, the drinking culture, unemployment and the ascending money problem, all are very well put, without any subjectivity or exaggeration.<br /><br />There are some points in the film that are not necessarily easy to comprehend and tie to each other, but the joint big picture is nonetheless rewarding. Not each one of the short stories is exciting or profound, but as said above, the big picture does not fail to deliver the feeling of \"real life\" and captivate the viewer. I happen to think in a calm moment: What is happening in the lives of all these people on the street? Well, this is what is happening. Movies like this are good to feed your imaginative power. It would be safe to assume this film could apply to the life in many countries, but it particularly reflects Finland as it is, and pretty damn well.<br /><br />One comment about the acting: Being the fan of Finnish cinema I am, I\\'ve never seen any of these actors on any other movie, but I found the acting in this feature right next door to perfect overall. Maybe not a masterpiece, but a very good try by the entire crew. I\\'ll be keeping an eye on the future releases of the director and the cast..<br /><br />7,5 / 10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the text"
      ],
      "metadata": {
        "id": "4RqzuQ8Vecxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    return word_tokenize(text)  # Tokenize\n",
        "\n",
        "train_reviews = [preprocess_text(review) for review in train_reviews]\n",
        "test_reviews = [preprocess_text(review) for review in test_reviews]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhI6QvLFeFq1",
        "outputId": "d2bb11cd-9e18-4aa4-e147-99fb77d9e863"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction\n",
        "Using Bag of Words"
      ],
      "metadata": {
        "id": "yPEqXuXLgMME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
        "X_train = vectorizer.fit_transform(train_reviews)\n",
        "X_test = vectorizer.transform(test_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GTXvhwGeHPY",
        "outputId": "590af2ce-084e-4bd2-b9fa-a2628d1ab833"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a Classifier"
      ],
      "metadata": {
        "id": "xYE0cbgKgUnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ApoQDU9aoZR1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fUI1_sWaoY5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "tqLlRViIfby_",
        "outputId": "dd7fa4ba-e85f-472a-e10c-eb2aaeb51a16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Evaluating the model"
      ],
      "metadata": {
        "id": "l8GwdwPcgmGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "report = classification_report(test_labels, predicted_labels)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLJ9DA7HgXFE",
        "outputId": "2b73d729-7676-40d7-f63c-addd58f2df6a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86944\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87     12500\n",
            "           1       0.87      0.86      0.87     12500\n",
            "\n",
            "    accuracy                           0.87     25000\n",
            "   macro avg       0.87      0.87      0.87     25000\n",
            "weighted avg       0.87      0.87      0.87     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction\n",
        "Uisng Word Embeddings - Global vectors (GloVe)"
      ],
      "metadata": {
        "id": "TeaxjK_xhUY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "#!unzip glove.6B.zip"
      ],
      "metadata": {
        "id": "pNnCBHMvgwEo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 10000\n",
        "maxlen = 100\n",
        "embedding_dim = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(train_reviews)\n",
        "sequences = tokenizer.texts_to_sequences(train_reviews)\n",
        "X_train = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(test_reviews)\n",
        "X_test = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "train_labels = np.asarray(train_labels)\n",
        "test_labels = np.asarray(test_labels)"
      ],
      "metadata": {
        "id": "QLakCbqai0CI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained GloVe embeddings\n",
        "embeddings_index = {}\n",
        "with open('glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "metadata": {
        "id": "Ji6rhNBCjugV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "qtHum2aGkS2z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "id": "pcnNrJTkkcSL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, train_labels, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluation\n",
        "test_loss, test_acc = model.evaluate(X_test, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz4odjniklWv",
        "outputId": "4cc44070-bd2c-472f-99a3-47bdcdf875e0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 187s 292ms/step - loss: 0.5450 - accuracy: 0.7199 - val_loss: 1.0407 - val_accuracy: 0.4384\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 164s 263ms/step - loss: 0.4185 - accuracy: 0.8096 - val_loss: 0.6048 - val_accuracy: 0.6736\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 159s 254ms/step - loss: 0.3798 - accuracy: 0.8296 - val_loss: 0.4530 - val_accuracy: 0.7734\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 162s 259ms/step - loss: 0.3553 - accuracy: 0.8435 - val_loss: 0.5603 - val_accuracy: 0.7150\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 159s 254ms/step - loss: 0.3342 - accuracy: 0.8540 - val_loss: 0.6238 - val_accuracy: 0.6968\n",
            "782/782 [==============================] - 33s 43ms/step - loss: 0.3933 - accuracy: 0.8215\n",
            "Test accuracy: 0.8214799761772156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KUpER_Zckms7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AqdT-5SuoNG7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}